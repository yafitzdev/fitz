# fitz_ai/engines/clara/config/default.yaml
#
# Default configuration for CLaRa engine.
#
# CLaRa (Compression-based Language Retrieval and Answering) compresses
# documents into memory tokens for efficient retrieval and generation.
#
# This default uses:
#   - apple/CLaRa-7B-E2E model (requires GPU with ~16GB VRAM)
#   - Local inference via HuggingFace transformers

clara:

  # ===========================================================================
  # Model
  # ===========================================================================
  # HuggingFace model variants:
  #   - apple/CLaRa-7B-Base (compression only)
  #   - apple/CLaRa-7B-Instruct (instruction-tuned)
  #   - apple/CLaRa-7B-E2E (full retrieval + generation)

  model:
    model_name_or_path: "apple/CLaRa-7B-E2E"
    variant: "e2e"
    device: "cuda"
    torch_dtype: "bfloat16"
    trust_remote_code: true
    load_in_8bit: false
    load_in_4bit: false

  # ===========================================================================
  # Compression
  # ===========================================================================
  # Compression rate options: 4, 16, 32, 64, 128
  # Higher = smaller but may lose information
  # Note: CLaRa compresses whole documents, not chunks

  compression:
    compression_rate: 16
    doc_max_length: 256
    num_memory_tokens: null

  # ===========================================================================
  # Retrieval
  # ===========================================================================

  retrieval:
    top_k: 5
    candidate_pool_size: 20
    differentiable_topk: false

  # ===========================================================================
  # Generation
  # ===========================================================================

  generation:
    max_new_tokens: 256
    temperature: 0.7
    top_p: 0.9
    do_sample: true

  # ===========================================================================
  # Knowledge Base
  # ===========================================================================

  knowledge_base_path: null
  cache_compressed_docs: true

  # ===========================================================================
  # Ingestion
  # ===========================================================================
  # CLaRa compresses whole documents (not chunks).
  # Parser converts files to text before compression.

  ingest:
    ingester:
      plugin_name: local

    collection: default
